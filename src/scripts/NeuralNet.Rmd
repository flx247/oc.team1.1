---
title: "R Notebook"
output: html_notebook
---

```{r include=FALSE}
# Create list with required libraries
libraries <- c("dplyr", "readr", "reticulate", "ggplot2", "Metrics", "tidyverse", "glmnet", "e1071", "lubridate", "keras")


# Loop through each library and check if it's installed, if not, install it and then load it to include in this project
for (lib in libraries)
{
  if (!require(lib, character.only = TRUE))
  {
    install.packages(lib)
    library(lib, character.only = TRUE)
  }
}

# Install the reticulate package if you haven't already
if (!requireNamespace("reticulate", quietly = TRUE)) {
  install.packages("reticulate")
}

# Custom function to check if a Conda environment exists
condaenv_exists <- function(env_name) {
  conda_envs <- conda_list()
  return(env_name %in% conda_envs$name)
}

# Check if conda is installed, if not, install miniconda
conda_envs <- conda_list()
if (length(conda_envs) == 0) {
  install_miniconda()
}

# Create a specific Python environment if it doesn't exist
if (!condaenv_exists("r-reticulate")) {
  conda_create("r-reticulate", python_version = "3.8")
}

```

```{r}
df <- read_csv("../data/data_clean.csv", show_col_types = FALSE)
```


```{r}
# Use the created Python environment
use_condaenv("r-reticulate", required = TRUE)

```

Preparing data once more in a different configuration
```{r include=FALSE}
# Preparation of independent variables ('features') by dummy coding the categorical variables
features <- as_tibble(model.matrix(Umsatz ~ as.factor(Warengruppe) +  as.factor(Wochentag) + as.factor(Monat) + Datum + Bewoelkung + Temperatur + KielerWoche + Windgeschwindigkeit, df))
names(features)

# Construction of prepared data set 
prepared_data <- tibble(label=df$Umsatz, features)  
# inclusion of the dependent variable ('label')

```

Now since this is a different data type as the previously used one for the LR and SVM, we need to create the basic, training and validation data sets again:
```{r}
set.seed(42)
prepared_data_shuffled <- prepared_data %>%
  sample_frac(1)

n_total_NN <- nrow(prepared_data_shuffled)
n_training_NN <- floor(0.7 * n_total_NN)
n_validation_NN <- floor(0.2 * n_total_NN)

```


Here we need to split the features and labels for training, validation and test data sets.
```{r}
training_features <-
  prepared_data_shuffled %>% select(-label) %>% slice(1:n_training_NN)

validation_features <-
  prepared_data_shuffled %>% select(-label) %>% slice((n_training_NN + 1):(n_training_NN + n_validation_NN))

test_features <-
  prepared_data_shuffled %>% select(-label) %>% slice((n_training_NN + n_validation_NN + 1):n_total_NN)

training_label <-
  prepared_data_shuffled %>% select(label) %>% slice(1:n_training_NN)

validation_label <-
  prepared_data_shuffled %>% select(label) %>% slice((n_training_NN + 1):(n_training_NN + n_validation_NN))

test_label <-
  prepared_data_shuffled %>% select(label) %>% slice((n_training_NN + n_validation_NN + 1):n_total_NN)

```


```{r}
# Check the dimensions of the dataframes
cat("Training features dimensions:", dim(training_features), "\n")
cat("Validation features dimensions:",
    dim(validation_features),
    "\n")
cat("Test features dimensions:", dim(test_features), "\n")
cat("\n")
cat("Training label dimensions:", dim(training_label), "\n")
cat("Validation label dimensions:", dim(validation_label), "\n")
cat("Test label dimensions:", dim(test_label), "\n")
```

Now let's go on to train the Neural Network!
### Definition des Neuronalen Netzes
```{python include=FALSE}
# Import needed Python libraries and functions
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import InputLayer, Dense, BatchNormalization, Dropout
from tensorflow.keras.optimizers import Adam

# The argument "input_shape" for the definition of the input layer must include the number input variables (features) used for the model. To automatically calculate this number, we use the  function `r.training_features.keys()`, which returns the list of variable names of the dataframe `training_features`. Then, the function `len()` returns the length of this list of variable names (i.e. the number of variables in the input).

model_1 = Sequential([
  InputLayer(input_shape=(len(r.training_features.keys()), )),
  BatchNormalization(),
  Dense(16, activation='tanh'),
  Dense(8, activation='relu'),
  Dense(2)
])

# model_2 = Sequential([
#   InputLayer(input_shape=(len(r.training_features.keys()), )),
#   BatchNormalization(),
#   Dense(10, activation='relu'),
#   Dense(4, activation='relu'),
#   Dense(1)
# ])
# 
# model_3 = Sequential([
#   InputLayer(input_shape=(len(r.training_features.keys()), )),
#   BatchNormalization(),
#   Dense(10, activation='relu'),
#   Dense(4, activation='relu'),
#   Dense(1)
# ])

# Ausgabe einer Zusammenfassung zur Form des Modells, das geschaetzt wird (nicht notwendig)
# model_1.summary()
# model_2.summary()
# model_3.summary()

```


### Schätzung des neuronalen Netzes
```{python}

# Definition der Kosten-(Loss-)Funktion und der Optimierungsfunktion mit seinen Hyperparametern
 model_1.compile(loss="mse", optimizer=Adam(learning_rate=0.01))
 # model_2.compile(loss="mse", optimizer=Adam(learning_rate=0.001))
 # model_3.compile(loss="mse", optimizer=Adam(learning_rate=0.001))

# Schaetzung des Modells
history_1 = model_1.fit(r.training_features, r.training_label, epochs=750,
                    validation_data = (r.validation_features, r.validation_label), verbose=0)

# history_2 = model_1.fit(r.training_features, r.training_label, epochs=200,
#                     validation_data = (r.validation_features, r.validation_label), verbose=0)
#                     
# history_3 = model_1.fit(r.training_features, r.training_label, epochs=300,
#                     validation_data = (r.validation_features, r.validation_label), verbose=0)

# Ggf. Speichern des geschaetzten Modells
# model_1.save("../ML_models/mod_nn_2.h5")
# model_2.save("../ML_models/mod_nn_3.h5")
model_1.save("../ML_models/mod_nn_16.h5")

```

### Auswertung der Modelloptimierung
```{r}
# Grafische Ausgabe der Modelloptimierung

# create data
data_1 <- data.frame(val_loss = unlist(py$history_1$history$val_loss),
                  loss = unlist(py$history_1$history$loss))

# data_2 <- data.frame(val_loss = unlist(py$history_2$history$val_loss),
#                   loss = unlist(py$history_2$history$loss))
# 
# data_3 <- data.frame(val_loss = unlist(py$history_3$history$val_loss),
#                   loss = unlist(py$history_3$history$loss))


# Plot
ggplot(data_1[-(1:10),]) +
  geom_line( aes(x=1:length(val_loss), y=val_loss, colour = "Validation Loss" )) +
  geom_line( aes(x=1:length(loss), y=loss, colour = "Training Loss" )) +
  scale_colour_manual( values = c("Training Loss"="blue", "Validation Loss"="red") ) +
  labs(title="Loss Function Values During Optimization") +
  xlab("Iteration Number") +
  ylab("Loss") 

# ggplot(data_2[-(1:10),]) +
#   geom_line( aes(x=1:length(val_loss), y=val_loss, colour = "Validation Loss" )) +
#   geom_line( aes(x=1:length(loss), y=loss, colour = "Training Loss" )) +
#   scale_colour_manual( values = c("Training Loss"="blue", "Validation Loss"="red") ) +
#   labs(title="Loss Function Values During Optimization") +
#   xlab("Iteration Number") +
#   ylab("Loss") 
# 
# ggplot(data_3[-(1:10),]) +
#   geom_line( aes(x=1:length(val_loss), y=val_loss, colour = "Validation Loss" )) +
#   geom_line( aes(x=1:length(loss), y=loss, colour = "Training Loss" )) +
#   scale_colour_manual( values = c("Training Loss"="blue", "Validation Loss"="red") ) +
#   labs(title="Loss Function Values During Optimization") +
#   xlab("Iteration Number") +
#   ylab("Loss") 
```


### Auswertung der Schätzergebnisse ###
```{r}
# test <- load_model_hdf5("../ML_models/mod_nn_3.h5")
# model <- py$model_1



# Schätzung der (normierten) Preise für die Trainings- und Testdaten
training_predictions <- py$model_1$predict(training_features)
validation_predictions <- py$model_1$predict(validation_features)
test_predictions <- py$model_1$predict(test_features)



# Vergleich der Gütekriterien für die Traingings- und Testdaten
cat(paste0("MAPE on the Training Data:\t", format(mape(training_label[[1]], training_predictions), digits=3, nsmall=2)))
cat(paste0("\nMAPE on the Validation Data:\t", format(mape(validation_label[[1]], validation_predictions), digits=3, nsmall=2)))


```


```{r}

## Grafischer Vergleich der vorhergesagten und der tatsächlichen Preise für die Trainings- und Testdaten

# Zusammenstellung der Daten für die Plots
data_train <- data.frame(prediction = training_predictions/1000, actual = training_label[[1]]/1000)
data_test <- data.frame(prediction = validation_predictions/1000, actual = validation_label[[1]]/1000)

# Plot der Ergebnisse der Trainingsdaten
ggplot(data_train[1:100,]) +
  geom_line( aes(x=1:length(prediction), y=prediction, colour = "Predicted Values" )) +
  geom_line( aes(x=1:length(actual), y=actual, colour = "Actual Values" )) +
  scale_colour_manual( values = c("Predicted Values"="blue", "Actual Values"="red") ) +
  labs(title="Predicted and Actual Values for the Training Data") +
  xlab("Case Number") +
  ylab("Umsatz") 

# Plot der Ergebnisse der Validierungsdaten
ggplot(data_test[1:100,]) +
  geom_line( aes(x=1:length(prediction), y=prediction, colour = "Predicted Values" )) +
  geom_line( aes(x=1:length(actual), y=actual, colour = "Actual Values" )) +
  scale_colour_manual( values = c("Predicted Values"="blue", "Actual Values"="red") ) +
  labs(title="Predicted and Actual Values for the Test Data") +
  xlab("Case Number") +
  ylab("Umsatz") 


```

```{r}
# Vorhersage für einen einzelnen Fall
cat(paste0("Vorhergesagter Umsatz:\t", round(validation_predictions[100])))
cat(paste0("\nTatsächlicher Umsatz:\t", validation_label[[1]][100]))

# model_1.save("../ML_models/mod_nn_6.h5")
```



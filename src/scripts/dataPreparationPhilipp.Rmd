---
title: "dataPreparationPhilipp"
author: "Philipp Meisinger, Olav Cornelius, Alexander Ruoff, Felix Wehkamp"
date: "`r Sys.Date()`"
output: html_document
---

## Datenaufbereitung und Visualisierung
We have to install the Python environment in order to run the following pieces of code.
```{r message=FALSE, warning=FALSE, include=FALSE}
# Create list with required libraries
libraries <- c("dplyr", "readr", "ggplot2", "tidyverse", "lubridate", "VIM")


# Loop through each library and check if it's installed, if not, install it and then load it to include in this project
for (lib in libraries)
{
  if (!require(lib, character.only = TRUE))
  {
    install.packages(lib)
    library(lib, character.only = TRUE)
  }
}

```

### Data Import

```{r include=FALSE}
# Storing Data sets as data frames

revenue <- read.csv('../data/umsatzdaten_gekuerzt.csv')
kiwo <- read.csv('../data/kiwo.csv')
ferien <- read.csv('../data/schulferienSH.csv')
weather <- read.csv('../data/weather.csv')
prediction_2019 <- read.csv('../data/prediction_template.csv')

```


### Joining in the Test data set.
The way we are to predict the "Umsatz" values for the times between the 2019-06-08 and the 2019-07-30 is by filling out the values we know in that time frame as well. So we'll include this time frame in the data preparation step, so that we can later on split the data set and keep this one as the test data set.

```{r include=FALSE}
df_prep <- full_join(revenue, prediction_2019, by = "Datum") %>%
  mutate(Warengruppe.x = ifelse(is.na(Warengruppe.x), Warengruppe.y, Warengruppe.x)) %>%
  mutate(Umsatz.x = ifelse(is.na(Umsatz.x), Umsatz.y, Umsatz.x))

df_prep <- df_prep %>% 
  rename(Umsatz = Umsatz.x, Warengruppe = Warengruppe.x)

df_prep <- select(df_prep, -Warengruppe.y)
df_prep <- select(df_prep, -Umsatz.y)

```

### Joining the kiwo data

Replacing all instances of Kiwo = NA with Kiwo = 0 Reformating Column KielerWoche to boolean values the weather data with the df containing revenue and kiwo

```{r include=FALSE}
df_prep <- left_join(df_prep, kiwo, by = "Datum") %>%
  replace_na(list(KielerWoche = 0)) %>%
  mutate(KielerWoche = ifelse(KielerWoche == 1, TRUE, FALSE))

```


```{r include=FALSE}
df_prep <- left_join(df_prep, weather, by = "Datum")

```


```{r}
# Deleting Column Wettercode from df:
df_prep <- select(df_prep, -Wettercode)

```

### Cleaning up the revenue data to convert Datum column to correct data type (i.e. char -\> date)

```{r include=FALSE}
df_prep$Datum <- as.Date(df_prep$Datum, format = "%Y-%m-%d")

```

### Converting the "Warengruppe" to char, as the algorithm might interpret the numeric values as ordered, while they are categorial.

```{r include=FALSE}
df_prep <- df_prep %>%
  mutate(Warengruppe = ifelse(Warengruppe == 1, "Brot", Warengruppe)) %>%
  mutate(Warengruppe = ifelse(Warengruppe == 2, "Brötchen", Warengruppe)) %>%
  mutate(Warengruppe = ifelse(Warengruppe == 3, "Croissant", Warengruppe)) %>%
  mutate(Warengruppe = ifelse(Warengruppe == 4, "Konditorei", Warengruppe)) %>%
  mutate(Warengruppe = ifelse(Warengruppe == 5, "Kuchen", Warengruppe)) %>%
  mutate(Warengruppe = ifelse(Warengruppe == 6, "Saisonbrot", Warengruppe))

prediction_2019 <- prediction_2019 %>%
  mutate(Warengruppe = ifelse(Warengruppe == 1, "Brot", Warengruppe)) %>%
  mutate(Warengruppe = ifelse(Warengruppe == 2, "Brötchen", Warengruppe)) %>%
  mutate(Warengruppe = ifelse(Warengruppe == 3, "Croissant", Warengruppe)) %>%
  mutate(Warengruppe = ifelse(Warengruppe == 4, "Konditorei", Warengruppe)) %>%
  mutate(Warengruppe = ifelse(Warengruppe == 5, "Kuchen", Warengruppe)) %>%
  mutate(Warengruppe = ifelse(Warengruppe == 6, "Saisonbrot", Warengruppe))
```

### Adding weekday column to data set

```{r include=FALSE}
df_prep$Wochentag <- weekdays(df_prep$Datum)
```

### Adding holiday column to data set

```{r include=FALSE}
ferien$Datum <- as.Date(ferien$Datum, format = "%Y-%m-%d")

df_prep <- left_join(df_prep, ferien, by = "Datum") %>%
  replace_na(list(FerienSH = 0)) %>%
  mutate(FerienSH = ifelse(FerienSH == 1, TRUE, FALSE))
```

### Adding Month variable
```{r}
df_prep$Monat <- month(df_prep$Datum)


# df_prep <- df_prep[df_prep$Monat == 6 | df_prep$Monat == 7, ]
# df
```


```{r}

df_prep_lag <- df_prep %>%
  arrange(Datum, Warengruppe) %>%
  group_by(Warengruppe) %>%
  mutate(value_prev_year = lag(Umsatz, default = NA, n = 365)) %>%
  
  ungroup()



df_prep_lag$value_prev_year <- ifelse(is.na(df_prep_lag$value_prev_year), df_prep_lag$Umsatz, df_prep_lag$value_prev_year)


```


### This helps us figure out if we have NA values in the dataset

```{r include=FALSE}
any(is.na(df_prep))

any(is.na(df_prep$Bewoelkung))

any(is.na(df_prep$Temperatur))
any(is.na(df_prep$Windgeschwindigkeit))
any(is.na(df_prep$Wettercode))

missing_values <- df_prep %>%
  filter(is.na(Temperatur) | is.na(Bewoelkung) | is.na(Windgeschwindigkeit))

```

### Data Imputation
```{r}

# VIM Aggregation Plot
df_prep %>%
  aggr(combined=TRUE, numbers=TRUE)

# Listwise deletion
# df_deletion <- na.omit(df_prep)
# df_deletion %>%
#  aggr(combined=TRUE, numbers=TRUE)

# VIM Hot-Deck Imputation
df_hotdeck_1 <- df_prep %>%  hotdeck()
df_hotdeck_1 %>%
  aggr(combined=TRUE, numbers=TRUE)

df_hotdeck_1_clean <- df_hotdeck_1 %>%
  select(-ends_with('_imp'))


df_hotdeck_1_lag <- df_prep_lag %>% hotdeck()

df_hotdeck_1_clean_lag <- df_hotdeck_1_lag %>%
  select(-ends_with('_imp'))

 # ggplot(df_hotdeck1) +
 #  geom_point(aes(
 #    x=Temperatur,
 #    y=Umsatz,
 #    color=Temperatur_imp
 #    )
 #  )
# 
# df_hotdeck2 <- df_prep %>% 
#   hotdeck(ord_var = "Datum")
# 
# df_hotdeck2 %>%
#   aggr(combined=TRUE, numbers=TRUE)

# ggplot(df_hotdeck2) +
#  geom_point(aes(
#    x=Bewoelkung,
#    y=Temperatur,
#    color=Temperatur_imp
#    )
#  )
# 
# sleep_hotdeck3 <- sleep_hotdeck2 %>%  hotdeck(ord_var = "Sleep")
# sleep_hotdeck3 %>% aggr(combined=TRUE, numbers=TRUE)

# VIM Iterative Robust Model Imputation (IRMI)
# df_irmi <- df_prep %>%  irmi(df_prep$Windgeschwindigkeit)
# ggplot(sleep_irmi) +
#   geom_point(aes(x=Sleep, y=Dream, color=Sleep_imp))


# Impact
# cor(sleep_deletion$Sleep, sleep_deletion$Dream)
# cor(df_hotdeck1$Datum, df_hotdeck1$Temperatur, use = "complete.obs")
# cor(df_hotdeck2$Sleep, sleep_hotdeck2$Temperatur, use = "complete.obs")
# cor(df_hotdeck3$Sleep, sleep_hotdeck3$Temperatur, use = "complete.obs")
# cor(df_irmi$Sleep, sleep_irmi$Dream)
```


```{r}
any(is.na(df_hotdeck_1_clean))

df_hotdeck_1_clean <- df_hotdeck_1_clean %>%
  arrange(Datum)

# Add test data set to clean data:

# prediction_2019$Datum <- as.Date(prediction_2019$Datum, format = "%Y-%m-%d")
# 
# 
# df_hotdeck_1_clean <- full_join(df_hotdeck_1_clean, prediction_2019, by = "Datum") %>%
#   mutate(Warengruppe.x = ifelse(is.na(Warengruppe.x), Warengruppe.y, Warengruppe.x)) %>%
#   mutate(Umsatz.x = ifelse(is.na(Umsatz.x), Umsatz.y, Umsatz.x))
#   
# df_hotdeck_1_clean <- df_hotdeck_1_clean %>% 
#   rename(Umsatz = Umsatz.x, Warengruppe = Warengruppe.x)
# 
# 
# df_hotdeck_1_clean <- select(df_hotdeck_1_clean, -Warengruppe.y)
# df_hotdeck_1_clean <- select(df_hotdeck_1_clean, -Umsatz.y)


```


```{r}
# Add test data set to lag data set:
# 
# df_hotdeck_1_clean_lag <- full_join(df_hotdeck_1_clean_lag, prediction_2019, by = "Datum") %>%
#   mutate(Warengruppe.x = ifelse(is.na(Warengruppe.x), Warengruppe.y, Warengruppe.x)) %>%
#   mutate(Umsatz.x = ifelse(is.na(Umsatz.x), Umsatz.y, Umsatz.x))
#   
# df_hotdeck_1_clean_lag <- df_hotdeck_1_clean_lag %>% 
#   rename(Umsatz = Umsatz.x, Warengruppe = Warengruppe.x)
# 
# 
# df_hotdeck_1_clean_lag <- select(df_hotdeck_1_clean_lag, -Warengruppe.y)
# df_hotdeck_1_clean_lag <- select(df_hotdeck_1_clean_lag, -Umsatz.y)


```





### Deleting all rows that contain even one NA value (This section will be replaced with data imputation later on.)

```{r include=FALSE}
# Check for complete cases
# complete_rows <- complete.cases(df_prep)

# Subset the data frame to keep only complete rows
# clean_df <- df_prep[complete_rows, ]

# write_csv(clean_df, "../data/data.csv")
write_csv(df_hotdeck_1_clean, "../data/data_clean.csv")
write_csv(df_hotdeck_1_clean_lag, "../data/data_clean_lag.csv")

#From here on out I'll work with the clean_df data set. Once the imputation step is implemented, the following code can be used for both.
```